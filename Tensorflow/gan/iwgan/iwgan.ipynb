{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0303 15:37:24.924027 4590425536 deprecation.py:323] From <ipython-input-1-3c4f46c1a93b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0303 15:37:24.924958 4590425536 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0303 15:37:24.926431 4590425536 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0303 15:37:25.105515 4590425536 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0303 15:37:25.108256 4590425536 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0303 15:37:25.154123 4590425536 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True) \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['out/', 'model/']:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0303 15:37:25.605237 4590425536 deprecation.py:506] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py:187: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "mb_size = 32\n",
    "Z_dim = 10\n",
    "X_dim = mnist.train.images.shape[1] # 784\n",
    "lam = 10\n",
    "n_disc = 5\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1./tf.sqrt(in_dim/2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([X_dim, 128]))\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "D_W2 = tf.Variable(xavier_init([128, 1]))\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "\n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2]\n",
    "\n",
    "Z = tf.placeholder(tf.float32, shape=[None, Z_dim])\n",
    "\n",
    "G_W1 = tf.Variable(xavier_init([Z_dim, 128]))\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "\n",
    "G_W2 = tf.Variable(xavier_init([128, X_dim]))\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2]\n",
    "\n",
    "def generator(z):\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob)\n",
    "    return G_prob\n",
    "\n",
    "def discriminator(X):\n",
    "    D_h1 = tf.nn.relu(tf.matmul(X, D_W1) + D_b1)\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n",
    "    return D_logit # 不使用 sigmoid\n",
    "\n",
    "def sample_Z(m,n):\n",
    "    return np.random.uniform(-1., 1., size=[m,n])\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "    return fig\n",
    "\n",
    "G_sample = generator(Z)\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(G_sample)\n",
    "\n",
    "eps = tf.random_uniform([mb_size, 1], minval=0., maxval=1.)\n",
    "X_inter = eps*X + (1. - eps)*G_sample\n",
    "grad = tf.gradients(discriminator(X_inter), [X_inter])[0] # 所有的 weight\n",
    "grad_norm = tf.sqrt(tf.reduce_sum((grad)**2, axis=1))\n",
    "grad_pen = lam*tf.reduce_mean((grad_norm - 1)**2)\n",
    "\n",
    "D_loss = -(tf.reduce_mean(D_real) - tf.reduce_mean(D_fake)) + grad_pen # D_real 與 D_fake 越遠越好\n",
    "G_loss = -tf.reduce_mean(D_fake)\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5).minimize(D_loss, var_list=theta_D) # 使用 Adam\n",
    "G_solver = tf.train.AdamOptimizer(learning_rate=0.0001, beta1=0.5).minimize(G_loss, var_list=theta_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "# saver.restore(sess, \"model/save_net.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0 [D loss:1.233] [G loss:0.6728]\n",
      "iter:1000 [D loss:-3.845] [G loss:0.1338]\n",
      "iter:2000 [D loss:-2.632] [G loss:-0.3145]\n",
      "iter:3000 [D loss:-2.162] [G loss:-0.4983]\n",
      "iter:4000 [D loss:-2.145] [G loss:-0.6747]\n",
      "iter:5000 [D loss:-2.099] [G loss:-0.8692]\n",
      "iter:6000 [D loss:-1.849] [G loss:-1.015]\n",
      "iter:7000 [D loss:-1.793] [G loss:-0.9601]\n",
      "iter:8000 [D loss:-1.71] [G loss:-0.9164]\n",
      "iter:9000 [D loss:-1.972] [G loss:-0.8961]\n",
      "iter:10000 [D loss:-1.578] [G loss:-0.9491]\n",
      "iter:11000 [D loss:-1.707] [G loss:-0.4466]\n",
      "iter:12000 [D loss:-2.06] [G loss:-0.1195]\n",
      "iter:13000 [D loss:-1.999] [G loss:-0.4045]\n",
      "iter:14000 [D loss:-2.161] [G loss:-0.2075]\n",
      "iter:15000 [D loss:-1.907] [G loss:-0.102]\n",
      "iter:16000 [D loss:-1.925] [G loss:-0.167]\n",
      "iter:17000 [D loss:-1.823] [G loss:-0.07738]\n",
      "iter:18000 [D loss:-1.791] [G loss:0.06274]\n",
      "iter:19000 [D loss:-1.765] [G loss:0.208]\n",
      "iter:20000 [D loss:-1.932] [G loss:0.1694]\n",
      "iter:21000 [D loss:-1.623] [G loss:0.03835]\n",
      "iter:22000 [D loss:-1.681] [G loss:-0.06566]\n",
      "iter:23000 [D loss:-1.876] [G loss:-0.009057]\n",
      "iter:24000 [D loss:-1.722] [G loss:-0.1288]\n",
      "iter:25000 [D loss:-1.533] [G loss:-0.4884]\n",
      "iter:26000 [D loss:-1.42] [G loss:-0.669]\n",
      "iter:27000 [D loss:-1.723] [G loss:-0.5705]\n",
      "iter:28000 [D loss:-1.531] [G loss:-0.8986]\n",
      "iter:29000 [D loss:-1.425] [G loss:-0.9464]\n",
      "iter:30000 [D loss:-1.449] [G loss:-1.197]\n",
      "iter:31000 [D loss:-1.734] [G loss:-0.9309]\n",
      "iter:32000 [D loss:-1.721] [G loss:-0.9055]\n",
      "iter:33000 [D loss:-1.637] [G loss:-1.087]\n",
      "iter:34000 [D loss:-1.354] [G loss:-1.11]\n",
      "iter:35000 [D loss:-1.632] [G loss:-1.109]\n",
      "iter:36000 [D loss:-1.365] [G loss:-1.02]\n",
      "iter:37000 [D loss:-1.586] [G loss:-1.204]\n",
      "iter:38000 [D loss:-1.416] [G loss:-1.202]\n",
      "iter:39000 [D loss:-1.525] [G loss:-1.267]\n",
      "iter:40000 [D loss:-1.6] [G loss:-1.553]\n",
      "iter:41000 [D loss:-1.474] [G loss:-1.399]\n",
      "iter:42000 [D loss:-1.289] [G loss:-1.343]\n",
      "iter:43000 [D loss:-1.544] [G loss:-1.526]\n",
      "iter:44000 [D loss:-1.359] [G loss:-1.301]\n",
      "iter:45000 [D loss:-1.521] [G loss:-1.69]\n",
      "iter:46000 [D loss:-1.042] [G loss:-1.643]\n",
      "iter:47000 [D loss:-1.277] [G loss:-1.538]\n",
      "iter:48000 [D loss:-1.425] [G loss:-1.464]\n",
      "iter:49000 [D loss:-1.189] [G loss:-1.935]\n",
      "iter:50000 [D loss:-1.241] [G loss:-1.595]\n",
      "iter:51000 [D loss:-1.342] [G loss:-1.712]\n",
      "iter:52000 [D loss:-1.458] [G loss:-1.491]\n",
      "iter:53000 [D loss:-1.118] [G loss:-1.537]\n",
      "iter:54000 [D loss:-1.155] [G loss:-1.643]\n",
      "iter:55000 [D loss:-1.192] [G loss:-1.757]\n",
      "iter:56000 [D loss:-1.325] [G loss:-1.678]\n",
      "iter:57000 [D loss:-1.306] [G loss:-1.588]\n",
      "iter:58000 [D loss:-1.103] [G loss:-1.63]\n",
      "iter:59000 [D loss:-1.371] [G loss:-1.685]\n",
      "iter:60000 [D loss:-1.319] [G loss:-1.658]\n",
      "iter:61000 [D loss:-1.42] [G loss:-1.42]\n",
      "iter:62000 [D loss:-1.248] [G loss:-1.5]\n",
      "iter:63000 [D loss:-1.128] [G loss:-1.48]\n",
      "iter:64000 [D loss:-1.106] [G loss:-1.572]\n",
      "iter:65000 [D loss:-1.165] [G loss:-1.686]\n",
      "iter:66000 [D loss:-1.303] [G loss:-1.609]\n",
      "iter:67000 [D loss:-1.202] [G loss:-1.603]\n",
      "iter:68000 [D loss:-1.219] [G loss:-1.652]\n",
      "iter:69000 [D loss:-0.8816] [G loss:-1.567]\n",
      "iter:70000 [D loss:-1.292] [G loss:-1.748]\n",
      "iter:71000 [D loss:-1.107] [G loss:-1.868]\n",
      "iter:72000 [D loss:-1.217] [G loss:-1.4]\n",
      "iter:73000 [D loss:-1.211] [G loss:-1.413]\n",
      "iter:74000 [D loss:-0.9476] [G loss:-1.392]\n",
      "iter:75000 [D loss:-1.24] [G loss:-1.206]\n",
      "iter:76000 [D loss:-0.9164] [G loss:-0.9972]\n",
      "iter:77000 [D loss:-1.217] [G loss:-1.123]\n",
      "iter:78000 [D loss:-1.251] [G loss:-1.477]\n",
      "iter:79000 [D loss:-1.253] [G loss:-1.127]\n",
      "iter:80000 [D loss:-1.329] [G loss:-1.066]\n",
      "iter:81000 [D loss:-1.092] [G loss:-1.213]\n",
      "iter:82000 [D loss:-1.309] [G loss:-0.9307]\n",
      "iter:83000 [D loss:-1.406] [G loss:-1.108]\n",
      "iter:84000 [D loss:-1.165] [G loss:-1.004]\n",
      "iter:85000 [D loss:-1.057] [G loss:-1.08]\n",
      "iter:86000 [D loss:-1.21] [G loss:-0.9025]\n",
      "iter:87000 [D loss:-1.054] [G loss:-1.17]\n",
      "iter:88000 [D loss:-1.007] [G loss:-0.9384]\n",
      "iter:89000 [D loss:-1.166] [G loss:-1.097]\n",
      "iter:90000 [D loss:-1.107] [G loss:-1.154]\n",
      "iter:91000 [D loss:-1.162] [G loss:-1.261]\n",
      "iter:92000 [D loss:-0.9597] [G loss:-0.9219]\n",
      "iter:93000 [D loss:-1.02] [G loss:-1.038]\n",
      "iter:94000 [D loss:-1.176] [G loss:-1.109]\n",
      "iter:95000 [D loss:-1.104] [G loss:-0.9646]\n",
      "iter:96000 [D loss:-1.032] [G loss:-0.9107]\n",
      "iter:97000 [D loss:-1.168] [G loss:-0.8553]\n",
      "iter:98000 [D loss:-1.087] [G loss:-0.9432]\n",
      "iter:99000 [D loss:-0.8262] [G loss:-0.7715]\n",
      "iter:100000 [D loss:-0.9281] [G loss:-0.7468]\n",
      "iter:101000 [D loss:-1.005] [G loss:-0.8468]\n",
      "iter:102000 [D loss:-1.148] [G loss:-0.9831]\n",
      "iter:103000 [D loss:-1.001] [G loss:-0.8005]\n",
      "iter:104000 [D loss:-0.9219] [G loss:-1.031]\n",
      "iter:105000 [D loss:-1.103] [G loss:-0.8279]\n",
      "iter:106000 [D loss:-0.9874] [G loss:-0.7526]\n",
      "iter:107000 [D loss:-1.008] [G loss:-0.4784]\n",
      "iter:108000 [D loss:-0.9656] [G loss:-0.9079]\n",
      "iter:109000 [D loss:-1.199] [G loss:-0.6411]\n",
      "iter:110000 [D loss:-1.071] [G loss:-0.752]\n",
      "iter:111000 [D loss:-1.04] [G loss:-0.6959]\n",
      "iter:112000 [D loss:-1.166] [G loss:-0.8728]\n",
      "iter:113000 [D loss:-0.9828] [G loss:-0.707]\n",
      "iter:114000 [D loss:-1.048] [G loss:-0.5604]\n",
      "iter:115000 [D loss:-0.9036] [G loss:-0.7573]\n",
      "iter:116000 [D loss:-1.058] [G loss:-0.7026]\n",
      "iter:117000 [D loss:-1.053] [G loss:-0.7678]\n",
      "iter:118000 [D loss:-0.9095] [G loss:-0.8985]\n",
      "iter:119000 [D loss:-1.018] [G loss:-0.7503]\n",
      "iter:120000 [D loss:-1.041] [G loss:-0.8805]\n",
      "iter:121000 [D loss:-1.018] [G loss:-0.8627]\n",
      "iter:122000 [D loss:-0.9622] [G loss:-0.8947]\n",
      "iter:123000 [D loss:-0.8315] [G loss:-1.106]\n",
      "iter:124000 [D loss:-0.7756] [G loss:-0.9411]\n",
      "iter:125000 [D loss:-0.8825] [G loss:-1.192]\n",
      "iter:126000 [D loss:-1.086] [G loss:-1.394]\n",
      "iter:127000 [D loss:-0.7751] [G loss:-1.399]\n",
      "iter:128000 [D loss:-0.8772] [G loss:-1.091]\n",
      "iter:129000 [D loss:-0.9246] [G loss:-1.555]\n",
      "iter:130000 [D loss:-1.076] [G loss:-1.01]\n",
      "iter:131000 [D loss:-1.088] [G loss:-1.403]\n",
      "iter:132000 [D loss:-0.7594] [G loss:-1.292]\n",
      "iter:133000 [D loss:-0.8784] [G loss:-1.658]\n",
      "iter:134000 [D loss:-0.9696] [G loss:-1.488]\n",
      "iter:135000 [D loss:-0.8536] [G loss:-1.306]\n",
      "iter:136000 [D loss:-1.108] [G loss:-1.433]\n",
      "iter:137000 [D loss:-0.851] [G loss:-1.501]\n",
      "iter:138000 [D loss:-0.9411] [G loss:-1.565]\n",
      "iter:139000 [D loss:-0.8486] [G loss:-1.515]\n",
      "iter:140000 [D loss:-0.6869] [G loss:-1.871]\n",
      "iter:141000 [D loss:-0.9223] [G loss:-1.858]\n",
      "iter:142000 [D loss:-1.108] [G loss:-1.65]\n",
      "iter:143000 [D loss:-0.8265] [G loss:-1.537]\n",
      "iter:144000 [D loss:-0.9379] [G loss:-1.942]\n",
      "iter:145000 [D loss:-0.9943] [G loss:-1.59]\n",
      "iter:146000 [D loss:-0.9017] [G loss:-1.597]\n",
      "iter:147000 [D loss:-0.956] [G loss:-1.504]\n",
      "iter:148000 [D loss:-1.099] [G loss:-1.766]\n",
      "iter:149000 [D loss:-0.8324] [G loss:-1.695]\n",
      "iter:150000 [D loss:-0.7593] [G loss:-1.502]\n",
      "iter:151000 [D loss:-0.9981] [G loss:-1.904]\n",
      "iter:152000 [D loss:-0.8449] [G loss:-1.645]\n",
      "iter:153000 [D loss:-0.7362] [G loss:-1.647]\n",
      "iter:154000 [D loss:-0.9115] [G loss:-1.595]\n",
      "iter:155000 [D loss:-0.8201] [G loss:-1.827]\n",
      "iter:156000 [D loss:-1.022] [G loss:-1.888]\n",
      "iter:157000 [D loss:-0.7259] [G loss:-1.572]\n",
      "iter:158000 [D loss:-0.8906] [G loss:-1.737]\n",
      "iter:159000 [D loss:-1.025] [G loss:-1.763]\n",
      "iter:160000 [D loss:-0.8591] [G loss:-1.624]\n",
      "iter:161000 [D loss:-0.9768] [G loss:-1.797]\n",
      "iter:162000 [D loss:-1.041] [G loss:-1.814]\n",
      "iter:163000 [D loss:-0.8401] [G loss:-2.081]\n",
      "iter:164000 [D loss:-0.8584] [G loss:-2.007]\n",
      "iter:165000 [D loss:-0.9072] [G loss:-2.071]\n",
      "iter:166000 [D loss:-0.8951] [G loss:-1.689]\n",
      "iter:167000 [D loss:-0.8156] [G loss:-1.81]\n",
      "iter:168000 [D loss:-1.003] [G loss:-1.771]\n",
      "iter:169000 [D loss:-0.9024] [G loss:-1.874]\n",
      "iter:170000 [D loss:-0.8825] [G loss:-1.586]\n",
      "iter:171000 [D loss:-0.8537] [G loss:-1.866]\n",
      "iter:172000 [D loss:-0.8516] [G loss:-1.619]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4369e229d445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_disc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mX_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mG_solver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 930\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    931\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1153\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1329\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1320\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for it in range(1000000):   \n",
    "    for _ in range(n_disc):\n",
    "        X_mb, _ =  mnist.train.next_batch(mb_size)\n",
    "        _, D_l = sess.run([D_solver, D_loss], feed_dict={X:X_mb, Z:sample_Z(mb_size, Z_dim)})\n",
    "        \n",
    "    _, G_l = sess.run([G_solver, G_loss], feed_dict={Z:sample_Z(mb_size, Z_dim)})\n",
    "    \n",
    "    if it%1000==0:\n",
    "        print('iter:{} [D loss:{:.4}] [G loss:{:.4}]'.format(it, D_l, G_l))\n",
    "        \n",
    "    if it%1000==0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z:sample_Z(16, Z_dim)})\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        i+=1\n",
    "        \n",
    "    if it%1000==0:\n",
    "        save_path = saver.save(sess, \"model/save_net.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
