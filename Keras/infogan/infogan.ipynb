{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0225 15:56:28.832053 4650694080 deprecation.py:323] From <ipython-input-1-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0225 15:56:28.833268 4650694080 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0225 15:56:28.834394 4650694080 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0225 15:56:29.017152 4650694080 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0225 15:56:29.019919 4650694080 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0225 15:56:29.061546 4650694080 deprecation.py:323] From /Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../../MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Embedding, Concatenate\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, Flatten\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils, plot_model\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 28*28)/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 72)           0           input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          18688       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 784)          201488      leaky_re_lu_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 220,176\n",
      "Trainable params: 220,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 201,218\n",
      "Trainable params: 100,609\n",
      "Non-trainable params: 100,609\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 62)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 784)          220176      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            100609      model_3[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 10)           118282      model_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 439,067\n",
      "Trainable params: 338,458\n",
      "Non-trainable params: 100,609\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianfan/anaconda3/envs/spinningup/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "x_dim = X_train.shape[1] # 784\n",
    "z_dim = 62\n",
    "c_dim = 10\n",
    "h_dim = 128\n",
    "batch_size = 128\n",
    "\n",
    "x = Input(shape=(x_dim,))\n",
    "D_h = Dense(h_dim)(x)\n",
    "D_h = LeakyReLU(0.2)(D_h)\n",
    "D_o = Dense(1, activation='sigmoid')(D_h)\n",
    "DM = Model(x, D_o)\n",
    "\n",
    "Q_h = Dense(h_dim)(D_h)\n",
    "Q_h = LeakyReLU(0.2)(Q_h)\n",
    "Q_o = Dense(c_dim, activation='softmax')(Q_h)\n",
    "QM = Model(x, Q_o)\n",
    "\n",
    "z = Input(shape=(z_dim,))\n",
    "c = Input(shape=(c_dim,))\n",
    "G_h = Concatenate(axis=1)([z, c])\n",
    "G_h = Dense(h_dim*2)(G_h)\n",
    "G_h = LeakyReLU(0.2)(G_h)\n",
    "G_o = Dense(x_dim, activation='sigmoid')(G_h)\n",
    "GM = Model([z, c], G_o)\n",
    "\n",
    "# del DM\n",
    "# DM = load_model('DM.h5')\n",
    "# del QM\n",
    "# QM = load_model('QM.h5')\n",
    "# del GM\n",
    "# GM = load_model('GM.h5')\n",
    "\n",
    "def mutual_info_loss(c, c_given_x):\n",
    "    \"\"\"The mutual information metric we aim to minimize\"\"\"\n",
    "    eps = 1e-8\n",
    "    conditional_entropy = K.mean(- K.sum(K.log(c_given_x + eps) * c, axis=1))\n",
    "    entropy = K.mean(- K.sum(K.log(c + eps) * c, axis=1))\n",
    "    return conditional_entropy + entropy\n",
    "\n",
    "DM.trainable = True\n",
    "DM.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# QM.compile(loss=[mutual_info_loss], optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "g = GM([z, c])\n",
    "DM.trainable = False\n",
    "y = DM(g)\n",
    "c_given_x = QM(g)\n",
    "AM = Model([z, c], [y, c_given_x])\n",
    "AM.compile(loss=['binary_crossentropy', mutual_info_loss], optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "GM.summary()\n",
    "DM.summary()\n",
    "AM.summary()\n",
    "QM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0\n",
      "[D loss:1.379, acc:0.4023] [G loss:3.007, acc:0.9453] [Q loss:0.6517, acc:0.1094]\n",
      "\n",
      "iter:10000\n",
      "[D loss:0.6781, acc:0.6914] [G loss:3.512, acc:0.2031] [Q loss:1.346, acc:0.8828]\n",
      "\n",
      "iter:20000\n",
      "[D loss:0.2123, acc:0.9727] [G loss:24.74, acc:0.0] [Q loss:8.049, acc:0.09375]\n",
      "\n",
      "iter:30000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:31.95, acc:0.0] [Q loss:16.12, acc:0.1406]\n",
      "\n",
      "iter:40000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:33.1, acc:0.0] [Q loss:16.12, acc:0.07812]\n",
      "\n",
      "iter:50000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:33.68, acc:0.0] [Q loss:16.12, acc:0.04688]\n",
      "\n",
      "iter:60000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:33.39, acc:0.0] [Q loss:16.12, acc:0.0625]\n",
      "\n",
      "iter:70000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:32.67, acc:0.0] [Q loss:16.12, acc:0.1016]\n",
      "\n",
      "iter:80000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:32.96, acc:0.0] [Q loss:16.12, acc:0.08594]\n",
      "\n",
      "iter:90000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:32.09, acc:0.0] [Q loss:16.12, acc:0.1328]\n",
      "\n",
      "iter:100000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:32.09, acc:0.0] [Q loss:16.12, acc:0.1328]\n",
      "\n",
      "iter:110000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:33.1, acc:0.0] [Q loss:16.12, acc:0.07812]\n",
      "\n",
      "iter:120000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:32.52, acc:0.0] [Q loss:16.12, acc:0.1094]\n",
      "\n",
      "iter:130000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:32.67, acc:0.0] [Q loss:16.12, acc:0.1016]\n",
      "\n",
      "iter:140000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:33.24, acc:0.0] [Q loss:16.12, acc:0.07031]\n",
      "\n",
      "iter:150000\n",
      "[D loss:1.096e-07, acc:1.0] [G loss:31.95, acc:0.0] [Q loss:16.12, acc:0.1406]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c08d53f501cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mc_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mG_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m#     z_samples = sample_Z(batch_size, z_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1439\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "    return fig\n",
    "\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m,n])\n",
    "\n",
    "def sample_C(m, n):\n",
    "    return np.random.multinomial(1, n*[0.1], size=m).astype(np.float32)\n",
    "#     sampled_labels = np.random.randint(0, n, m).reshape(-1, 1)\n",
    "#     sampled_labels = np_utils.to_categorical(sampled_labels, num_classes=n)\n",
    "#     return sampled_labels\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "real = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "    \n",
    "i=0\n",
    "for it in range(1000000):\n",
    "    r = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    x_real = X_train[r]\n",
    "    \n",
    "    z_samples = sample_Z(batch_size, z_dim)\n",
    "    c_samples = sample_Z(batch_size, c_dim)\n",
    "    x_fake = GM.predict([z_samples, c_samples])\n",
    "    \n",
    "    D_loss_real, D_acc_real = DM.train_on_batch(x_real, real)\n",
    "    D_loss_fake, D_acc_fake = DM.train_on_batch(x_fake, fake)\n",
    "    \n",
    "    D_loss = 0.5*(D_loss_real + D_loss_fake)\n",
    "    D_acc = 0.5*(D_acc_real + D_acc_fake)\n",
    "    \n",
    "    z_samples = sample_Z(batch_size, z_dim)\n",
    "    c_samples = sample_C(batch_size, c_dim)\n",
    "    \n",
    "    G_loss, Q_loss, _, G_acc, Q_acc = AM.train_on_batch([z_samples, c_samples], [real, c_samples])\n",
    "    \n",
    "#     z_samples = sample_Z(batch_size, z_dim)\n",
    "#     c_samples = sample_C(batch_size, c_dim)\n",
    "    \n",
    "#     Q_loss, Q_acc = QM.train_on_batch([z_samples, c_samples], c_samples)\n",
    "    \n",
    "    if it%10000==0:\n",
    "        DM.save('DM.h5')\n",
    "        QM.save('QM.h5')\n",
    "        GM.save('GM.h5')\n",
    "        \n",
    "        for j in range(c_dim):\n",
    "            c_samples = np.ones((16,1))*j\n",
    "            c_samples = np_utils.to_categorical(c_samples, num_classes=c_dim)\n",
    "            samples = GM.predict([sample_Z(16, z_dim), c_samples])\n",
    "            fig = plot(samples)\n",
    "            plt.savefig('out/{}.png'.format(str(i).zfill(3) + '_' + str(j)), bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "        i+=1\n",
    "        \n",
    "        print('iter:{}'.format(it))\n",
    "        print('[D loss:{:.4}, acc:{:.4}] [G loss:{:.4}, acc:{:.4}] [Q loss:{:.4}, acc:{:.4}]'.format(D_loss, D_acc, G_loss, G_acc, Q_loss, Q_acc))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
